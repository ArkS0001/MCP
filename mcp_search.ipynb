{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQTvsNDM16r_",
        "outputId": "8f363c21-09a7-44b6-b106-c5ca1c2b5c7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting duckduckgo-search\n",
            "  Downloading duckduckgo_search-7.5.3-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting groq\n",
            "  Downloading groq-0.20.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from duckduckgo-search) (8.1.8)\n",
            "Collecting primp>=0.14.0 (from duckduckgo-search)\n",
            "  Downloading primp-0.14.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: lxml>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from duckduckgo-search) (5.3.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from groq) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (2.27.2)\n",
            "Downloading duckduckgo_search-7.5.3-py3-none-any.whl (20 kB)\n",
            "Downloading groq-0.20.0-py3-none-any.whl (124 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.9/124.9 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading primp-0.14.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: primp, duckduckgo-search, groq\n",
            "Successfully installed duckduckgo-search-7.5.3 groq-0.20.0 primp-0.14.0\n"
          ]
        }
      ],
      "source": [
        "pip install duckduckgo-search groq\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"GROQ_API_KEY\"] =\"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\"\n"
      ],
      "metadata": {
        "id": "zDqASxz418lY"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python\n",
        "import sys\n",
        "import json\n",
        "import os\n",
        "from duckduckgo_search import DDGS\n",
        "from groq import Groq\n",
        "\n",
        "def perform_search(query, max_results=5):\n",
        "    \"\"\"Perform a DuckDuckGo search for the query.\"\"\"\n",
        "    with DDGS() as ddgs:\n",
        "        results = ddgs.text(query, max_results=max_results)\n",
        "    return results\n",
        "\n",
        "def format_search_results(results):\n",
        "    \"\"\"Format search results into a plain text context string.\"\"\"\n",
        "    formatted = \"\"\n",
        "    for res in results:\n",
        "        title = res.get(\"title\", \"No Title\")\n",
        "        url = res.get(\"href\", \"No URL\")\n",
        "        snippet = res.get(\"body\", \"No snippet available\")\n",
        "        formatted += f\"Title: {title}\\nURL: {url}\\nSnippet: {snippet}\\n\\n\"\n",
        "    return formatted.strip()\n",
        "\n",
        "def build_prompt(query, search_context):\n",
        "    \"\"\"Build a prompt that includes the search results as context.\"\"\"\n",
        "    prompt = (\n",
        "        \"Answer the following question using only the context provided below.\\n\\n\"\n",
        "        \"Search Results:\\n\"\n",
        "        f\"{search_context}\\n\\n\"\n",
        "        \"Question: \" + query + \"\\nAnswer:\"\n",
        "    )\n",
        "    return prompt\n",
        "\n",
        "def call_groq(prompt):\n",
        "    \"\"\"Send the prompt to Groq API and return the generated answer.\"\"\"\n",
        "    groq_api_key = os.environ.get(\"GROQ_API_KEY\")\n",
        "    if not groq_api_key:\n",
        "        raise ValueError(\"GROQ_API_KEY environment variable is not set.\")\n",
        "    client = Groq(api_key=groq_api_key)\n",
        "    # Select an appropriate Groq model – adjust as needed\n",
        "    model = \"llama-3.3-70b-versatile\"\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        max_completion_tokens=150,\n",
        "        temperature=0.7,\n",
        "        top_p=1,\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "class MCPServer:\n",
        "    \"\"\"A simple MCP server that integrates DuckDuckGo search and Groq API.\"\"\"\n",
        "\n",
        "    def process_request(self, request_str: str) -> str:\n",
        "        # Parse the JSON request\n",
        "        try:\n",
        "            data = json.loads(request_str)\n",
        "            query = data.get(\"message\", \"\")\n",
        "            if not query:\n",
        "                return json.dumps({\"error\": \"No message provided\"})\n",
        "        except Exception as e:\n",
        "            return json.dumps({\"error\": f\"Invalid JSON format: {str(e)}\"})\n",
        "\n",
        "        # Perform a search using DuckDuckGo\n",
        "        search_results = perform_search(query)\n",
        "        search_context = format_search_results(search_results)\n",
        "\n",
        "        # Build a prompt that includes the search results\n",
        "        prompt = build_prompt(query, search_context)\n",
        "\n",
        "        # Call the Groq API with the constructed prompt\n",
        "        groq_response = call_groq(prompt)\n",
        "\n",
        "        # Build and return the final JSON response\n",
        "        response = {\n",
        "            \"query\": query,\n",
        "            \"search_context\": search_context,\n",
        "            \"answer\": groq_response\n",
        "        }\n",
        "        return json.dumps(response)\n",
        "\n",
        "def main():\n",
        "    server = MCPServer()\n",
        "    # Continuously read from STDIN\n",
        "    for line in sys.stdin:\n",
        "        if line.strip():\n",
        "            output = server.process_request(line.strip())\n",
        "            print(output)\n",
        "            sys.stdout.flush()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "COMFIPc319-z"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install duckduckgo-search groq mcp-agent nest_asyncio\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9whXcR9W3IGu",
        "outputId": "ee178c81-35f8-43a9-f34c-971faf23f6ac"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: duckduckgo-search in /usr/local/lib/python3.11/dist-packages (7.5.3)\n",
            "Requirement already satisfied: groq in /usr/local/lib/python3.11/dist-packages (0.20.0)\n",
            "Requirement already satisfied: mcp-agent in /usr/local/lib/python3.11/dist-packages (0.0.11)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.11/dist-packages (1.6.0)\n",
            "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from duckduckgo-search) (8.1.8)\n",
            "Requirement already satisfied: primp>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from duckduckgo-search) (0.14.0)\n",
            "Requirement already satisfied: lxml>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from duckduckgo-search) (5.3.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from groq) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq) (4.12.2)\n",
            "Requirement already satisfied: fastapi>=0.115.6 in /usr/local/lib/python3.11/dist-packages (from mcp-agent) (0.115.12)\n",
            "Requirement already satisfied: instructor>=1.7.7 in /usr/local/lib/python3.11/dist-packages (from mcp-agent) (1.7.7)\n",
            "Requirement already satisfied: mcp>=1.2.1 in /usr/local/lib/python3.11/dist-packages (from mcp-agent) (1.5.0)\n",
            "Requirement already satisfied: numpy>=2.1.3 in /usr/local/lib/python3.11/dist-packages (from mcp-agent) (2.2.4)\n",
            "Requirement already satisfied: opentelemetry-distro>=0.50b0 in /usr/local/lib/python3.11/dist-packages (from mcp-agent) (0.52b1)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http>=1.29.0 in /usr/local/lib/python3.11/dist-packages (from mcp-agent) (1.31.1)\n",
            "Requirement already satisfied: pydantic-settings>=2.7.0 in /usr/local/lib/python3.11/dist-packages (from mcp-agent) (2.8.1)\n",
            "Requirement already satisfied: pyyaml>=6.0.2 in /usr/local/lib/python3.11/dist-packages (from mcp-agent) (6.0.2)\n",
            "Requirement already satisfied: rich>=13.9.4 in /usr/local/lib/python3.11/dist-packages (from mcp-agent) (13.9.4)\n",
            "Requirement already satisfied: scikit-learn>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from mcp-agent) (1.6.1)\n",
            "Requirement already satisfied: typer>=0.15.1 in /usr/local/lib/python3.11/dist-packages (from mcp-agent) (0.15.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi>=0.115.6->mcp-agent) (0.46.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.9.1 in /usr/local/lib/python3.11/dist-packages (from instructor>=1.7.7->mcp-agent) (3.11.14)\n",
            "Requirement already satisfied: docstring-parser<1.0,>=0.16 in /usr/local/lib/python3.11/dist-packages (from instructor>=1.7.7->mcp-agent) (0.16)\n",
            "Requirement already satisfied: jinja2<4.0.0,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from instructor>=1.7.7->mcp-agent) (3.1.6)\n",
            "Requirement already satisfied: jiter<0.9,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from instructor>=1.7.7->mcp-agent) (0.8.2)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.52.0 in /usr/local/lib/python3.11/dist-packages (from instructor>=1.7.7->mcp-agent) (1.66.5)\n",
            "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from instructor>=1.7.7->mcp-agent) (2.27.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.32.3 in /usr/local/lib/python3.11/dist-packages (from instructor>=1.7.7->mcp-agent) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10.0.0,>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from instructor>=1.7.7->mcp-agent) (9.0.0)\n",
            "Requirement already satisfied: httpx-sse>=0.4 in /usr/local/lib/python3.11/dist-packages (from mcp>=1.2.1->mcp-agent) (0.4.0)\n",
            "Requirement already satisfied: sse-starlette>=1.6.1 in /usr/local/lib/python3.11/dist-packages (from mcp>=1.2.1->mcp-agent) (2.2.1)\n",
            "Requirement already satisfied: uvicorn>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from mcp>=1.2.1->mcp-agent) (0.34.0)\n",
            "Requirement already satisfied: opentelemetry-api~=1.12 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-distro>=0.50b0->mcp-agent) (1.31.1)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.52b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-distro>=0.50b0->mcp-agent) (0.52b1)\n",
            "Requirement already satisfied: opentelemetry-sdk~=1.13 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-distro>=0.50b0->mcp-agent) (1.31.1)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.52b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation==0.52b1->opentelemetry-distro>=0.50b0->mcp-agent) (0.52b1)\n",
            "Requirement already satisfied: packaging>=18.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation==0.52b1->opentelemetry-distro>=0.50b0->mcp-agent) (24.2)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation==0.52b1->opentelemetry-distro>=0.50b0->mcp-agent) (1.17.2)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-semantic-conventions==0.52b1->opentelemetry-instrumentation==0.52b1->opentelemetry-distro>=0.50b0->mcp-agent) (1.2.18)\n",
            "Requirement already satisfied: importlib-metadata<8.7.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api~=1.12->opentelemetry-distro>=0.50b0->mcp-agent) (8.6.1)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-http>=1.29.0->mcp-agent) (1.69.2)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.31.1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-http>=1.29.0->mcp-agent) (1.31.1)\n",
            "Requirement already satisfied: opentelemetry-proto==1.31.1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-http>=1.29.0->mcp-agent) (1.31.1)\n",
            "Requirement already satisfied: protobuf<6.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-proto==1.31.1->opentelemetry-exporter-otlp-proto-http>=1.29.0->mcp-agent) (5.29.4)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings>=2.7.0->mcp-agent) (1.0.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.9.4->mcp-agent) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.9.4->mcp-agent) (2.18.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.6.0->mcp-agent) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.6.0->mcp-agent) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.6.0->mcp-agent) (3.6.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.15.1->mcp-agent) (1.5.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor>=1.7.7->mcp-agent) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor>=1.7.7->mcp-agent) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor>=1.7.7->mcp-agent) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor>=1.7.7->mcp-agent) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor>=1.7.7->mcp-agent) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor>=1.7.7->mcp-agent) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor>=1.7.7->mcp-agent) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2<4.0.0,>=3.1.4->instructor>=1.7.7->mcp-agent) (3.0.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=13.9.4->mcp-agent) (0.1.2)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.52.0->instructor>=1.7.7->mcp-agent) (4.67.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.3->instructor>=1.7.7->mcp-agent) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.3->instructor>=1.7.7->mcp-agent) (2.3.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api~=1.12->opentelemetry-distro>=0.50b0->mcp-agent) (3.21.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import asyncio\n",
        "import nest_asyncio\n",
        "\n",
        "nest_asyncio.apply()\n",
        "\n",
        "from duckduckgo_search import DDGS\n",
        "from groq import Groq\n",
        "from mcp_agent.app import MCPApp as OriginalMCPApp\n",
        "from mcp_agent.agents.agent import Agent\n",
        "\n",
        "# Define a minimal patched MCPApp that does not pass extra kwargs\n",
        "class MCPAppPatched(OriginalMCPApp):\n",
        "    def __init__(self):\n",
        "        # Call the original constructor with no extra parameters.\n",
        "        OriginalMCPApp.__init__(self)\n",
        "\n",
        "# Define an asynchronous DuckDuckGo search tool\n",
        "async def duckduckgo_search_tool(query: str) -> str:\n",
        "    with DDGS() as ddgs:\n",
        "        results = ddgs.text(query, max_results=5)\n",
        "    formatted = \"\"\n",
        "    for res in results:\n",
        "        title = res.get(\"title\", \"No Title\")\n",
        "        url = res.get(\"href\", \"No URL\")\n",
        "        snippet = res.get(\"body\", \"No snippet available\")\n",
        "        formatted += f\"Title: {title}\\nURL: {url}\\nSnippet: {snippet}\\n\\n\"\n",
        "    return formatted.strip()\n",
        "\n",
        "# Define an asynchronous Groq chat tool for text generation\n",
        "async def groq_chat_tool(prompt: str) -> str:\n",
        "    groq_api_key = os.environ.get(\"GROQ_API_KEY\")\n",
        "    if not groq_api_key:\n",
        "        raise ValueError(\"GROQ_API_KEY environment variable is not set. Please set it in this notebook.\")\n",
        "    client = Groq(api_key=groq_api_key)\n",
        "    model = \"llama-3.3-70b-versatile\"\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        max_completion_tokens=150,\n",
        "        temperature=0.7,\n",
        "        top_p=1,\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "async def main():\n",
        "    # Use our patched MCPApp that does not pass extra kwargs\n",
        "    app = MCPAppPatched()\n",
        "\n",
        "    # Create an agent with two tools: \"search\" and \"generate\"\n",
        "    agent = Agent(\n",
        "        name=\"search_agent\",\n",
        "        instruction=\"You are a search agent that first retrieves search results and then uses a language model to generate a final answer.\",\n",
        "        tools={\n",
        "            \"search\": duckduckgo_search_tool,\n",
        "            \"generate\": groq_chat_tool,\n",
        "        }\n",
        "    )\n",
        "\n",
        "    async with app.run():\n",
        "        user_query = \"What is the latest news about AI breakthroughs?\"\n",
        "\n",
        "        # Step 1: Use the search tool to retrieve search results\n",
        "        search_results = await agent.call_tool(\"search\", user_query)\n",
        "\n",
        "        # Step 2: Build a prompt that includes the search context\n",
        "        combined_prompt = (\n",
        "            \"Answer the following question using only the context provided below.\\n\\n\"\n",
        "            \"Search Results:\\n\" + search_results + \"\\n\\n\"\n",
        "            \"Question: \" + user_query + \"\\nAnswer:\"\n",
        "        )\n",
        "\n",
        "        # Step 3: Use the Groq chat tool to generate the final answer\n",
        "        final_answer = await agent.call_tool(\"generate\", combined_prompt)\n",
        "\n",
        "        print(\"Final Answer:\")\n",
        "        print(final_answer)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    asyncio.run(main())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "LZVhoW553Oz0",
        "outputId": "d3e83379-b5b6-442b-8dfd-02fa8d91a858"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "object.__init__() takes exactly one argument (the instance to initialize)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-ce608c33e372>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nest_asyncio.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mtask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_future\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_until_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nest_asyncio.py\u001b[0m in \u001b[0;36mrun_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m     96\u001b[0m                 raise RuntimeError(\n\u001b[1;32m     97\u001b[0m                     'Event loop stopped before Future completed.')\n\u001b[0;32m---> 98\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/asyncio/futures.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__log_traceback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception_tb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/asyncio/tasks.py\u001b[0m in \u001b[0;36m__step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    275\u001b[0m                 \u001b[0;31m# We use the `send` method directly, because coroutines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m                 \u001b[0;31m# don't have `__iter__` and `__next__` methods.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-ce608c33e372>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;31m# Create an agent with two tools: \"search\" and \"generate\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     agent = Agent(\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"search_agent\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0minstruction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"You are a search agent that first retrieves search results and then uses a language model to generate a final answer.\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/mcp_agent/agents/agent.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, instruction, server_names, functions, connection_persistence, human_input_callback, context, **kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     ):\n\u001b[0;32m---> 51\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m     52\u001b[0m             \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mserver_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mserver_names\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/mcp_agent/mcp/mcp_aggregator.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, server_names, connection_persistence, context, name, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mNote\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mserver\u001b[0m \u001b[0mnames\u001b[0m \u001b[0mmust\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mresolvable\u001b[0m \u001b[0mby\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgen_client\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mspecified\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mserver\u001b[0m \u001b[0mregistry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \"\"\"\n\u001b[0;32m---> 85\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m     86\u001b[0m             \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/mcp_agent/context_dependent.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, context, **kwargs)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Context\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: object.__init__() takes exactly one argument (the instance to initialize)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the required package (run this cell first)\n",
        "!pip install duckduckgo-search\n",
        "\n",
        "# Define a simple agent class that holds a dictionary of tools.\n",
        "class SimpleAgent:\n",
        "    def __init__(self, tools: dict):\n",
        "        self.tools = tools\n",
        "\n",
        "    def call_tool(self, tool_name: str, input_str: str) -> str:\n",
        "        tool = self.tools.get(tool_name)\n",
        "        if not tool:\n",
        "            raise ValueError(f\"Tool '{tool_name}' not found.\")\n",
        "        return tool(input_str)\n",
        "\n",
        "# Define a synchronous DuckDuckGo search tool\n",
        "def duckduckgo_search_tool(query: str) -> str:\n",
        "    from duckduckgo_search import DDGS\n",
        "    with DDGS() as ddgs:\n",
        "        results = ddgs.text(query, max_results=5)\n",
        "    formatted = \"\"\n",
        "    for res in results:\n",
        "        title = res.get(\"title\", \"No Title\")\n",
        "        url = res.get(\"href\", \"No URL\")\n",
        "        snippet = res.get(\"body\", \"No snippet available\")\n",
        "        formatted += f\"Title: {title}\\nURL: {url}\\nSnippet: {snippet}\\n\\n\"\n",
        "    return formatted.strip()\n",
        "\n",
        "def main():\n",
        "    # Create an agent that only has a 'search' tool.\n",
        "    agent = SimpleAgent(tools={\"search\": duckduckgo_search_tool})\n",
        "\n",
        "    # Example user query.\n",
        "    user_query = \"Give me all information about small llms and give links also \"\n",
        "\n",
        "    # Use the agent to call the search tool.\n",
        "    search_results = agent.call_tool(\"search\", user_query)\n",
        "\n",
        "    print(\"Search Results:\")\n",
        "    print(search_results)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWnqXJln4cWY",
        "outputId": "8942e388-bb4f-4f92-b47f-471cfdbf1a7b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: duckduckgo-search in /usr/local/lib/python3.11/dist-packages (7.5.3)\n",
            "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from duckduckgo-search) (8.1.8)\n",
            "Requirement already satisfied: primp>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from duckduckgo-search) (0.14.0)\n",
            "Requirement already satisfied: lxml>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from duckduckgo-search) (5.3.1)\n",
            "Search Results:\n",
            "Title: Comprehensive List of Small LLMs - E2E Networks\n",
            "URL: https://www.e2enetworks.com/blog/comprehensive-list-of-small-llms-the-mini-giants-of-the-llm-world\n",
            "Snippet: Similarly, small LLMs also pose ethical challenges, which needs to be addressed. These considerations can be considered not only for small LLMs, but for LLMs in general. Data Protection: Ensuring user data privacy and protection is necessary, especially when dealing with sensitive personal information. Small LLMs need to be designed with ...\n",
            "\n",
            "Title: Here are 15+ Small LLMs that You can Run on Local Devices\n",
            "URL: https://www.analyticsvidhya.com/blog/2024/04/smallest-llms-that-you-can-run-on-local-devices/\n",
            "Snippet: Hugging Face Link: ALBERT. GPT-2 Small. Model Size: GPT-2 Small has around 117M parameters, significantly smaller than the larger GPT-2 models. Description: GPT-2 Small is a smaller version of the popular GPT-2 (Generative Pre-trained Transformer 2) model developed by OpenAI. While not as compact as some of the other models, GPT-2 Small is ...\n",
            "\n",
            "Title: The Best Small LLMs for Building Your Next App - Medium\n",
            "URL: https://medium.com/@alejandro7899871776/the-best-small-llms-for-building-your-next-app-460fc28b740b\n",
            "Snippet: Also, check out my blogs — I have been posting multiple articles on how to get the most out of your small LLMs running locally, along with many use cases and real implementations. AI. Llm.\n",
            "\n",
            "Title: Top 15 Small Language Models for 2025 - DataCamp\n",
            "URL: https://www.datacamp.com/blog/top-small-language-models\n",
            "Snippet: Small language models (SLMs) are compact, efficient, and don't need massive servers—unlike their large language models (LLMs) counterparts. They're built for speed and real-time performance and can run on our smartphones, tablets, or smartwatches. In this article, we'll examine the top 15 SLMs of 2025 and explore their strengths, weaknesses, and what makes each model unique.\n",
            "\n",
            "Title: Tiny LLMs, Giant Potential: A New Era of AI - Medium\n",
            "URL: https://medium.com/@JamesStakelum/tiny-llms-giant-potential-a-new-era-of-ai-0de46e15c4de\n",
            "Snippet: The rise of small LLMs. ... Except, hmmm, maybe I don't really want my toaster to give me the weather, or need my refrigerator to suggest recipes, so, okay, let's scratch those off the list ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from duckduckgo_search import DDGS\n",
        "from groq import Groq\n",
        "\n",
        "# A simple synchronous agent that holds tools in a dictionary.\n",
        "class SimpleAgent:\n",
        "    def __init__(self, tools: dict):\n",
        "        self.tools = tools\n",
        "\n",
        "    def call_tool(self, tool_name: str, input_str: str) -> str:\n",
        "        tool = self.tools.get(tool_name)\n",
        "        if not tool:\n",
        "            raise ValueError(f\"Tool '{tool_name}' not found.\")\n",
        "        return tool(input_str)\n",
        "\n",
        "# Synchronous DuckDuckGo search tool.\n",
        "def duckduckgo_search_tool(query: str) -> str:\n",
        "    with DDGS() as ddgs:\n",
        "        results = ddgs.text(query, max_results=5)\n",
        "    formatted = \"\"\n",
        "    for res in results:\n",
        "        title = res.get(\"title\", \"No Title\")\n",
        "        url = res.get(\"href\", \"No URL\")\n",
        "        snippet = res.get(\"body\", \"No snippet available\")\n",
        "        formatted += f\"Title: {title}\\nURL: {url}\\nSnippet: {snippet}\\n\\n\"\n",
        "    return formatted.strip()\n",
        "\n",
        "# Synchronous Groq chat tool for text generation.\n",
        "def groq_chat_tool(prompt: str) -> str:\n",
        "    groq_api_key = os.environ.get(\"GROQ_API_KEY\")\n",
        "    if not groq_api_key:\n",
        "        raise ValueError(\"GROQ_API_KEY is not set. Please set it in your environment.\")\n",
        "    client = Groq(api_key=groq_api_key)\n",
        "    model = \"llama-3.3-70b-versatile\"  # Choose an appropriate model from Groq.\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        max_completion_tokens=2048,\n",
        "        temperature=0.7,\n",
        "        top_p=1,\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "def main():\n",
        "    # Create a simple agent with two tools: one for searching and one for generating.\n",
        "    agent = SimpleAgent(tools={\n",
        "        \"search\": duckduckgo_search_tool,\n",
        "        \"generate\": groq_chat_tool,\n",
        "    })\n",
        "\n",
        "    print(\"Welcome to the MCP Agent!\")\n",
        "    print(\"Type 'exit' to quit.\\n\")\n",
        "    while True:\n",
        "        user_query = input(\"Enter your query: \").strip()\n",
        "        if user_query.lower() == \"exit\":\n",
        "            break\n",
        "\n",
        "        # Step 1: Use the search tool to get DuckDuckGo search results.\n",
        "        search_results = agent.call_tool(\"search\", user_query)\n",
        "\n",
        "        # Step 2: Build a prompt that includes the search results as context.\n",
        "        combined_prompt = (\n",
        "            \"Answer the following question using only the context provided below.\\n\\n\"\n",
        "            \"Search Results:\\n\" + search_results + \"\\n\\n\"\n",
        "            \"Question: \" + user_query + \"\\nAnswer:\"\n",
        "        )\n",
        "\n",
        "        # Step 3: Call the Groq chat tool with the combined prompt.\n",
        "        final_answer = agent.call_tool(\"generate\", combined_prompt)\n",
        "\n",
        "        print(\"\\nFinal Answer:\")\n",
        "        print(final_answer)\n",
        "        print(\"\\n\" + \"-\"*40 + \"\\n\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hFATwwME41gN",
        "outputId": "783c2e11-9781-4cd3-bf4f-125c183a3353"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to the MCP Agent!\n",
            "Type 'exit' to quit.\n",
            "\n",
            "Enter your query: i want to know latest tech on quantum computing also link it to th epage\n",
            "\n",
            "Final Answer:\n",
            "The latest developments in quantum computing include:\n",
            "\n",
            "1. **Quantum chemistry applications**: Enabling the computation of single-point energies of large molecular systems with unprecedented accuracy, which could accelerate drug discovery and materials design. [https://www.openaccessgovernment.org/the-latest-developments-in-quantum-computing-a-transformative-frontier/187748/](https://www.openaccessgovernment.org/the-latest-developments-in-quantum-computing-a-transformative-frontier/187748/)\n",
            "2. **Topological quantum processor**: An eight-qubit topological quantum processor has been unveiled by Microsoft and UC Santa Barbara researchers, marking a major step toward building a fully functional topological quantum computer. [https://scitechdaily.com/a-new-state-of-matter-just-changed-the-future-of-quantum-computing/](https://scitechdaily.com/a-new-state-of-matter-just-changed-the-future-of-quantum-computing/)\n",
            "3. **Google's Willow quantum chip**: A new quantum chip that outperformed even the world's best supercomputer on an advanced test. [https://www.forbes.com/councils/forbestechcouncil/2025/03/24/whats-next-after-ai-the-future-of-quantum/](https://www.forbes.com/councils/forbestechcouncil/2025/03/24/whats-next-after-ai-the-future-of-quantum/)\n",
            "4. **IBM's Eagle processor**: Featuring 127 qubits, and Google's Sycamore chip demonstrating quantum supremacy by solving a complex calculation in 200 seconds. [https://quantaintelligence.ai/2024/10/12/technology/latest-advancements-in-quantum-computing-technology](https://quantaintelligence.ai/2024/10/12/technology/latest-advancements-in-quantum-computing-technology)\n",
            "5. **Advancements in hardware and algorithms**: As of late 2024, quantum computing stands at the precipice of transformative advancements in hardware and algorithms, with impacts on cybersecurity, AI integration, and future industry trends. [https://methodologists.net/Exploring-the-Transformative-Advancements-in-Quantum-Computing-and-Their-Global-Impact-in-2024](https://methodologists.net/Exploring-the-Transformative-Advancements-in-Quantum-Computing-and-Their-Global-Impact-in-2024)\n",
            "\n",
            "These are the latest developments in quantum computing, and you can visit the linked pages for more information.\n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "Enter your query: how to integrate mcp with claude \n",
            "\n",
            "Final Answer:\n",
            "To integrate MCP with Claude, you can follow these steps:\n",
            "\n",
            "1. Start by visiting the Model Context Protocol (MCP) tutorials page, which provides guides on building MCP servers and clients, including using LLMs like Claude.\n",
            "2. Download the Claude Desktop App and install the Brave Search MCP tool by creating a configuration file and following the step-by-step tutorial.\n",
            "3. Watch the YouTube video on \"How to Set Up Model Context Protocol (MCP) with Claude AI\" for a visual guide.\n",
            "4. For Claude Desktop Users, add the Filesystem MCP Server by installing a pre-built server and following the quickstart guide.\n",
            "5. Use the Claude 3.7 MCP integration guide to initialize the client and set system prompts for a real-world application.\n",
            "\n",
            "These steps should help you integrate MCP with Claude.\n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "Enter your query: Difference between LoRA and QLoRA fine tuning\n",
            "\n",
            "Final Answer:\n",
            "The main difference between LoRA and QLoRA fine-tuning techniques is that QLoRA applies quantization to the low-rank matrices, which reduces the memory footprint of fine-tuning. This makes QLoRA more memory-efficient than LoRA, but it may sacrifice a little precision in the final model. LoRA is ideal when memory is a constraint but high precision is required, while QLoRA is perfect for scenarios where extreme memory efficiency is required and a little precision can be sacrificed. Additionally, LoRA may have slightly faster training times than QLoRA.\n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "Enter your query: list all the tools you are using to retrieve information\n",
            "\n",
            "Final Answer:\n",
            "Based on the provided context, the following tools are mentioned for retrieving information:\n",
            "\n",
            "1. Web search engines\n",
            "2. Library discovery tools\n",
            "3. Article indexes\n",
            "\n",
            "Additionally, the context mentions that there are more comprehensive lists of information gathering tools available, but it does not specify the exact tools. It refers to the following resources for more information:\n",
            "\n",
            "- Restackio's list of information retrieval tools\n",
            "- Medium's comprehensive list of information gathering tools\n",
            "- Resoomer's information tools\n",
            "- Alooba's information on information retrieval systems \n",
            "\n",
            "However, the specific tools mentioned in these resources are not provided in the given context.\n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "Enter your query: Give me all information about small llms and give links also \n",
            "\n",
            "Final Answer:\n",
            "Based on the search results, here's the information about small LLMs:\n",
            "\n",
            "1. **Comprehensive List of Small LLMs**: This article from E2E Networks discusses the importance of small LLMs and the ethical challenges they pose, including data protection and user privacy. [https://www.e2enetworks.com/blog/comprehensive-list-of-small-llms-the-mini-giants-of-the-llm-world](https://www.e2enetworks.com/blog/comprehensive-list-of-small-llms-the-mini-giants-of-the-llm-world)\n",
            "2. **Best Tiny, Small, and Compact LLMs**: This article from Geeky Gadgets lists some of the best small LLMs available, along with other resources on large language model technologies. [https://www.geeky-gadgets.com/the-best-tiny-small-and-compact-llms-currently-available/](https://www.geeky-gadgets.com/the-best-tiny-small-and-compact-llms-currently-available/)\n",
            "3. **Best Small LLMs for Building Your Next App**: This article on Medium discusses the best small LLMs for building apps, along with tips on how to get the most out of your small LLMs running locally. [https://medium.com/@alejandro7899871776/the-best-small-llms-for-building-your-next-app-460fc28b740b](https://medium.com/@alejandro7899871776/the-best-small-llms-for-building-your-next-app-460fc28b740b)\n",
            "4. **15+ Small LLMs that You Can Run on Local Devices**: This article from Analytics Vidhya lists over 15 small LLMs that can be run on local devices, including GPT-2 Small, which has around 117M parameters. [https://www.analyticsvidhya.com/blog/2024/04/smallest-llms-that-you-can-run-on-local-devices/](https://www.analyticsvidhya.com/blog/2024/04/smallest-llms-that-you-can-run-on-local-devices/)\n",
            "5. **Top 15 Small Language Models for 2025**: This article from DataCamp discusses the top 15 small language models for 2025, including their strengths, weaknesses, and what makes each model unique. [https://www.datacamp.com/blog/top-small-language-models](https://www.datacamp.com/blog/top-small-language-models)\n",
            "\n",
            "Some of the small LLMs mentioned in these articles include:\n",
            "\n",
            "* GPT-2 Small\n",
            "* ALBERT\n",
            "* Ferret 7B (a multimodal large language model from Apple)\n",
            "\n",
            "These articles provide a comprehensive overview of small LLMs, including their benefits, challenges, and applications.\n",
            "\n",
            "----------------------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-1cf88515330b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-15-1cf88515330b>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Type 'exit' to quit.\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0muser_query\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter your query: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muser_query\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"exit\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from duckduckgo_search import DDGS\n",
        "from groq import Groq\n",
        "\n",
        "# A simple synchronous agent that holds tools in a dictionary.\n",
        "class SimpleAgent:\n",
        "    def __init__(self, tools: dict):\n",
        "        self.tools = tools\n",
        "\n",
        "    def call_tool(self, tool_name: str, input_str: str) -> str:\n",
        "        tool = self.tools.get(tool_name)\n",
        "        if not tool:\n",
        "            raise ValueError(f\"Tool '{tool_name}' not found.\")\n",
        "        return tool(input_str)\n",
        "\n",
        "# Synchronous DuckDuckGo search tool.\n",
        "def duckduckgo_search_tool(query: str) -> str:\n",
        "    with DDGS() as ddgs:\n",
        "        results = ddgs.text(query, max_results=5)\n",
        "    formatted = \"\"\n",
        "    for res in results:\n",
        "        title = res.get(\"title\", \"No Title\")\n",
        "        url = res.get(\"href\", \"No URL\")\n",
        "        snippet = res.get(\"body\", \"No snippet available\")\n",
        "        formatted += f\"Title: {title}\\nURL: {url}\\nSnippet: {snippet}\\n\\n\"\n",
        "    return formatted.strip()\n",
        "\n",
        "# Synchronous Groq chat tool for text generation.\n",
        "def groq_chat_tool(prompt: str) -> str:\n",
        "    groq_api_key = os.environ.get(\"GROQ_API_KEY\")\n",
        "    if not groq_api_key:\n",
        "        raise ValueError(\"GROQ_API_KEY is not set. Please set it in your environment.\")\n",
        "    client = Groq(api_key=groq_api_key)\n",
        "    model = \"llama-3.3-70b-versatile\"  # Choose an appropriate model from Groq.\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        max_completion_tokens=2048,\n",
        "        temperature=0.7,\n",
        "        top_p=1,\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "def main():\n",
        "    # Create a simple agent with two tools: one for searching and one for generating.\n",
        "    agent = SimpleAgent(tools={\n",
        "        \"search\": duckduckgo_search_tool,\n",
        "        \"generate\": groq_chat_tool,\n",
        "    })\n",
        "\n",
        "    print(\"Welcome to the MCP Agent!\")\n",
        "    print(\"Type 'exit' to quit.\\n\")\n",
        "    while True:\n",
        "        user_query = input(\"Enter your query: \").strip()\n",
        "        if user_query.lower() == \"exit\":\n",
        "            break\n",
        "\n",
        "        # Step 1: Use the search tool to get DuckDuckGo search results.\n",
        "        search_results = agent.call_tool(\"search\", user_query)\n",
        "\n",
        "        # Step 2: Build a prompt that includes the search results as context.\n",
        "        combined_prompt = (\n",
        "            \"Answer the following question using only the context provided below.\\n\\n\"\n",
        "            \"Search Results:\\n\" + search_results + \"\\n\\n\"\n",
        "            \"Question: \" + user_query + \"\\nAnswer:\"\n",
        "        )\n",
        "\n",
        "        # Step 3: Call the Groq chat tool with the combined prompt.\n",
        "        final_answer = agent.call_tool(\"generate\", combined_prompt)\n",
        "\n",
        "        print(\"\\nFinal Answer:\")\n",
        "        print(final_answer)\n",
        "        print(\"\\nSources:\")\n",
        "        print(search_results)\n",
        "        print(\"\\n\" + \"-\"*40 + \"\\n\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjEgkxg07uje",
        "outputId": "5b8aee4d-aab5-4315-abea-e9083c965ce0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Welcome to the MCP Agent!\n",
            "Type 'exit' to quit.\n",
            "\n",
            "Enter your query: quantum tech latest 2025\n",
            "\n",
            "Final Answer:\n",
            "According to the search results, 2025 is expected to be a significant year for quantum technology, with predictions of huge advances in quantum computing. The United Nations has designated 2025 as the International Year of Quantum Science and Technology, highlighting the global focus on quantum advancements. Some of the expected developments include the integration of quantum technology, quantum-safe networking, and the expansion of the quantum conversation beyond computing to other market-ready opportunities. Investors and organizations are taking notice, with Google's new Willow quantum chip adding over $100B to its market cap. Overall, 2025 is expected to be a pivotal year for the quantum technology industry.\n",
            "\n",
            "Sources:\n",
            "Title: 2025 Expert Quantum Predictions — Quantum Computing\n",
            "URL: https://thequantuminsider.com/2024/12/31/2025-expert-quantum-predictions-quantum-computing/\n",
            "Snippet: Within a few hours of announcing its new Willow quantum chip, Google added over $100B to its market cap. Investors and organisations alike are waking up to the unprecedented compute power that quantum computers will enable. ... In 2025, we anticipate the quantum technology industry will hit pivotal milestones, particularly in the integration of ...\n",
            "\n",
            "Title: What's In Store In 2025: Ground-Breaking Tech And Quantum ... - Forbes\n",
            "URL: https://www.forbes.com/councils/forbestechcouncil/2025/02/25/whats-in-store-in-2025-ground-breaking-tech-and-quantum-computing/\n",
            "Snippet: I believe 2025 will be the year in which technology begins to fundamentally alter our vision of the future. 5G networks will shine, and quantum-safe networking will become a priority.\n",
            "\n",
            "Title: 7 Predictions For Quantum Resilience In 2025 - Forbes\n",
            "URL: https://www.forbes.com/councils/forbestechcouncil/2025/01/24/7-predictions-for-quantum-resilience-in-2025/\n",
            "Snippet: The designation of 2025 as the International Year of Quantum Science and Technology by the United Nations highlights the global focus on quantum advancements and the importance of PQC in securing ...\n",
            "\n",
            "Title: 2025 Will See Huge Advances in Quantum Computing. So What is a Quantum ...\n",
            "URL: https://thequantuminsider.com/2025/01/08/2025-will-see-huge-advances-in-quantum-computing-so-what-is-a-quantum-chip-and-how-does-it-work/\n",
            "Snippet: Head of Quantum Systems and Principal Research Scientist, CSIRO. In recent years, the field of quantum computing has been experiencing fast growth, with technological advances and large-scale investments regularly making the news. The United Nations has designated 2025 as the International Year of Quantum Science and Technology.\n",
            "\n",
            "Title: Big Ideas in Quantum For 2025\n",
            "URL: https://thequantuminsider.com/2024/12/23/big-ideas-in-quantum-for-2025/\n",
            "Snippet: These are not necessarily New Year's resolutions for 2025, rather the list includes ideas to consider, attitudes to take and warnings to heed. ... Quantum Technology Beyond Computing. In 2025, the quantum conversation will finally expand beyond computing. While quantum computers often dominate headlines, the real market-ready opportunities ...\n",
            "\n",
            "----------------------------------------\n",
            "\n",
            "Enter your query: exit\n"
          ]
        }
      ]
    }
  ]
}